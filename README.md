# Personal Finance Tracker Project

This project builds a complete data pipeline and warehouse to track and analyze personal financial transactions using the **Plaid API**. The goal is to apply modern data engineering and warehousing principles using a **medallion architecture** (Bronze â†’ Silver â†’ Gold) and implement **SCD Type 2** for dimension tracking.

---
## ğŸš€ Project Overview

- **Domain:** Personal Finance
- **Goal:** Build an end-to-end data warehouse to analyze and track financial transactions
- **Tools & Technologies:** Python, Pandas, SQL, PyODBC, Dotenv, Plaid data
- **Data Source:** JSON data exported from the **Plaid API**
- **Architecture:** Medallion Architecture (Bronze â†’ Silver â†’ Gold)
- **Database:** Microsoft SQL Server

---
## ğŸ”§ Tech Stack
- **Python** â€“ Data ingestion & transformation
- **SQL Server** â€“ DWH backend & procedural logic
- **Pandas** â€“ JSON flattening & preprocessing
- **T-SQL Stored Procedures** â€“ Gold layer logic
- **ODBC** â€“ Python-to-SQL connection
- **Version Control** â€“ Git & GitHub

---
## ğŸ—ï¸ Layers Explained

### ğŸ¥‰ Bronze Layer
- Raw Plaid JSON files are collected and stored
- No transformations applied

### ğŸ¥ˆ Silver Layer
- Data is flattened, cleaned, and validated using Python
- CSVs generated for cleaned transactions and accounts
- Inserted into SQL Server staging tables

### ğŸ¥‡ Gold Layer
- Star Schema designed with:
  - `fact_transactions`
  - `dim_account` (SCD Type 2)
  - `dim_date`
  - `dim_category`
- Stored Procedures handle loading with change detection & SCD logic
- Metadata logging for traceability

---
## ğŸ§± Schema Design
- ### Dimension Tables:
  - `dim_account`: All account-level metadata (type, holder, currency).
  - `dim_date`: Calendar table generated via recursive CTE.
  - `dim_category`: Extracted from transaction-level category array.
- ### Fact Table:
  - `fact_transactions`: Transaction fact table with FKs to dimensions and supporting attributes.
  
---
## ğŸ“Š Reporting Layer
- SQL views created for common analytics:
  - Total monthly spending
  - Top spending categories
  - Spending by merchant

---
## âœ… Key Features & Learnings

- ğŸ” **SCD Type 2 Implementation** in `dim_account` for historical tracking
- ğŸ›ï¸ **Star Schema** design to optimize analytics queries
- ğŸ“… Dynamic `dim_date` generation using Recursive CTE
- ğŸ“¦ **Stored Procedures** for Gold layer ETL logic
- ğŸ” Robust data cleaning and validation in Python
- ğŸ“„ Metadata logging for traceability of pipeline runs

---

## ğŸ§  Highlights & Learning Outcomes

- âœ… Implemented full **ETL** pipeline using Python and SQL Server
- âœ… Applied **Medallion Architecture** in a real-world scenario
- âœ… Designed a robust **star schema**
- âœ… Implemented **SCD-1** logic using SQL Server Stored Procedures
- âœ… Built **reporting views** for insights without dashboard tools
- âœ… Learned how to handle data quality issues (NaNs, type mismatches, key violations)
- âœ… Strengthened SQL Server stored procedure & CTE knowledge

---

## ğŸ“ Folder Structure

/plaid-dwh
â”‚
â”œâ”€â”€ /data
|   â”œâ”€â”€ /bronze
|   |     â””â”€â”€ transactions_2025-07-20_13-50-30.json
|   â”œâ”€â”€ /Silver
|   |     â”œâ”€â”€accounts_clean_2025-07-20_13-50-47.csv
|   |     â””â”€â”€transactions_clean_2025-07-20_13-50-47.csv
â”‚   
â”œâ”€â”€ /DBScripts
|   â”œâ”€â”€ DB_and_Schema_Creation_Scripts.sql
|   â”œâ”€â”€ Login_and_User_Creation.sql
|   â”œâ”€â”€ /silver
|   |     â””â”€â”€ ddl_silver.sql
â”‚   â”œâ”€â”€ /Gold
|   |     â”œâ”€â”€ ddl_gold.sql
â”‚   |     â”œâ”€â”€ Load_dim_date_table.sql
â”‚   |     â”œâ”€â”€ sp_load_dim_account_table.sql
â”‚   |     â”œâ”€â”€ sp_load_dim_category_table.sql
â”‚   |     â””â”€â”€ sp_load_fact_transactions_table.sql
â”‚   â”œâ”€â”€ /Reporting_Aggreated_Views
|   |     â”œâ”€â”€ Create_View__spent_by_category.sql
â”‚   |     â”œâ”€â”€ Create_View__spent_on_per_merchant.sql
â”‚   |     â”œâ”€â”€ Create_View_monthly_spent.sql
â”‚   |     â””â”€â”€ Create_View_monthly_spent_per_account.sql
â”‚
â”œâ”€â”€ /scripts
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ transform.py
â”‚   â””â”€â”€ load.py
â”‚
â”œâ”€â”€ /docs
â”‚   â””â”€â”€ architecture.png
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ Folder_Creation_Script.py
â”œâ”€â”€ test_plaid.py
â””â”€â”€ readme.md

---
## ğŸ› ï¸ Setup & Execution

1. Configure `.env` for database credentials
2. Place raw JSONs in `data/bronze`
3. Run `silver_cleaner.py` to clean and load data to Silver layer
4. Execute Gold layer stored procedures (or run `gold_loader.py`)
5. Query reporting views from SQL Server

---
## ğŸ“Œ Final Thoughts

This project simulates a **real-world finance data platform**, showcasing:
- Strong fundamentals in warehousing
- Data modeling best practices
- Hands-on pipeline building

---
## ğŸ”— Connect

If you liked this project or learned from it, feel free to connect with me or check out more of my work!
Linkedin: www.linkedin.com/in/ankitakirad
